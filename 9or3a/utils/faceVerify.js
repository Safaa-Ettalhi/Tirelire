const canvas = require('canvas');
const faceapi = require('face-api.js');
const path = require('path');
const fs = require('fs');

// Configuration de face-api.js pour Node.js
const { Canvas, Image, ImageData } = canvas;
faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

// Variable pour stocker l'√©tat de chargement des mod√®les
let modelsLoaded = false;

async function loadModels() {
    if (modelsLoaded) return;
    
    try {
        console.log('üîÑ Chargement des mod√®les d\'IA...');
        const modelPath = path.join(__dirname, '../models/face-api');
        
        await Promise.all([
            faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath),
            faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath),
            faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath)
        ]);
        
        modelsLoaded = true;
        console.log('‚úÖ Mod√®les d\'IA charg√©s avec succ√®s');
    } catch (error) {
        console.error('‚ùå Erreur lors du chargement des mod√®les:', error.message);
        throw error;
    }
}

async function compareFaces(image1Path, image2Path) {
    try {
        // V√©rifier que les fichiers d'images existent
        if (!fs.existsSync(image1Path) || !fs.existsSync(image2Path)) {
            console.log('‚ùå Fichiers d\'images non trouv√©s');
            return false;
        }

        console.log('üîç V√©rification faciale avec IA...');
        console.log('üì∏ Image 1:', image1Path);
        console.log('üì∏ Image 2:', image2Path);
        
        // Charger les mod√®les d'IA
        await loadModels();
        
        // Charger les images
        const img1 = await canvas.loadImage(image1Path);
        const img2 = await canvas.loadImage(image2Path);

        // D√©tecter les visages et extraire les descripteurs
        const detection1 = await faceapi
            .detectSingleFace(img1)
            .withFaceLandmarks()
            .withFaceDescriptor();
            
        const detection2 = await faceapi
            .detectSingleFace(img2)
            .withFaceLandmarks()
            .withFaceDescriptor();

        // V√©rifier si des visages ont √©t√© d√©tect√©s
        if (!detection1) {
            console.log('‚ùå Aucun visage d√©tect√© dans la premi√®re image');
            return false;
        }
        
        if (!detection2) {
            console.log('‚ùå Aucun visage d√©tect√© dans la deuxi√®me image');
            return false;
        }

        // Calculer la distance euclidienne entre les descripteurs
        const distance = faceapi.euclideanDistance(
            detection1.descriptor, 
            detection2.descriptor
        );
        
        // Seuil de similarit√© (ajustable)
        const threshold = 0.6; // Distance < 0.6 = m√™me personne
        const isSamePerson = distance < threshold;
        const similarity = Math.max(0, (1 - distance) * 100);
        
        console.log(`üìä Distance euclidienne: ${distance.toFixed(3)}`);
        console.log(`üìä Similarit√©: ${similarity.toFixed(1)}%`);
        console.log(`‚úÖ R√©sultat: ${isSamePerson ? 'M√™me personne' : 'Personnes diff√©rentes'}`);
        
        return isSamePerson;
        
    } catch (error) {
        console.error('‚ùå Erreur lors de la v√©rification faciale:', error.message);
        return false;
    }
}

module.exports = { compareFaces };
